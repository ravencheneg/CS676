{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eNan2LPxSh4g",
        "outputId": "6b91fd8e-6e2d-466e-e054-f7515d93a0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------- 1. Hybrid Feature Engineering -----------------\n",
        "\n",
        "class HybridCredibilityFeatures:\n",
        "    def __init__(self):\n",
        "        self.credible_domains = {\n",
        "            'nature.com': 1.0, 'science.org': 1.0, 'edu': 0.9,\n",
        "            'gov': 0.9, 'org': 0.7, 'com': 0.5,\n",
        "            'thelancet.com': 1.0, 'sciencedirect.com': 0.9,\n",
        "            'springer.com': 0.9, 'ieee.org': 0.9, 'acm.org': 0.9,\n",
        "            'nih.gov': 1.0, 'clinical-journal.com': 0.8,\n",
        "            'who.int': 1.0, 'nejm.org': 1.0, 'jamanetwork.com': 0.9,\n",
        "            'webmd.com': 0.6, 'wikipedia.org': 0.4,\n",
        "            'blogspot.com': 0.2, 'youtube.com': 0.2\n",
        "        }\n",
        "        self.academic_sites = {\n",
        "            'researchgate.net', 'academia.edu', 'scholar.google.com',\n",
        "            'arxiv.org', 'pubmed.ncbi.nlm.nih.gov', 'jstor.org'\n",
        "        }\n",
        "        self.sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "    def extract_urls(self, text):\n",
        "        url_pattern = r'https?://[^\\s]+'\n",
        "        return re.findall(url_pattern, text)\n",
        "\n",
        "    def score_url(self, url):\n",
        "        try:\n",
        "            domain = urlparse(url).netloc.lower()\n",
        "            base_domain = '.'.join(domain.split('.')[-2:])\n",
        "\n",
        "            if domain in self.academic_sites:\n",
        "                return 1.0\n",
        "            for credible_domain, score in self.credible_domains.items():\n",
        "                if credible_domain in domain or credible_domain in base_domain:\n",
        "                    return score\n",
        "            return 0.3  # Default for unknown\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def get_link_score(self, text):\n",
        "        urls = self.extract_urls(text)\n",
        "        if urls:\n",
        "            return max(self.score_url(url) for url in urls) * 100\n",
        "        return 0.0\n",
        "\n",
        "    def get_string_score(self, text):\n",
        "        clean_sentence = re.sub(r'https?://[^\\s]+', '', text)\n",
        "        sentiment_score = self.sid.polarity_scores(clean_sentence)['compound']\n",
        "        return round(100.0 - (abs(sentiment_score) * 90.0), 2)\n",
        "\n",
        "# ----------------- 2. Training & Testing Data -----------------\n",
        "\n",
        "training_data = {\n",
        "    'sentence': [\n",
        "        \"A study from NEJM suggests a link between this drug and reduced heart disease. https://www.nejm.org/some-article-id\",\n",
        "        \"My doctor says this supplement will boost my immune system. http://healthylifehacks.com/immune-booster\",\n",
        "        \"A new research paper on coffee is available at Harvard. https://harvard.edu/research/coffee-health\",\n",
        "        \"This new weight loss method is a miracle, as seen in this video. https://www.youtube.com/watch?v=12345\",\n",
        "        \"Vaccines for children are safe and effective, per the CDC. https://www.cdc.gov/vaccinesafety/\",\n",
        "        \"Detox tea benefits are explored in this blog. https://detox-guru.blogspot.com/2025/08/tea.html\"\n",
        "    ],\n",
        "    'human_score': [90.0, 30.0, 95.0, 20.0, 100.0, 40.0]\n",
        "}\n",
        "train_df = pd.DataFrame(training_data)\n",
        "\n",
        "test_data = {\n",
        "    'sentence': [\n",
        "        \"A breakthrough treatment for cancer is now available, according to this new study. http://www.breakthroughs-today.com/cancer-cure\",\n",
        "        \"The World Health Organization published a report on influenza. https://www.who.int/influenza/report\",\n",
        "        \"New research suggests probiotics are great for gut health. https://www.science.org/probiotics-study\",\n",
        "        \"My secret formula for staying young is available here: http://www.my-blog-for-money.net/secret\",\n",
        "        \"Doctors are in agreement about the incredible benefits of this new diet, as reported in this journal. https://www.clinical-journal.com/new-diet\"\n",
        "    ]\n",
        "}\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "# ----------------- 3. Feature Extraction -----------------\n",
        "\n",
        "fe = HybridCredibilityFeatures()\n",
        "\n",
        "train_df['link_score'] = train_df['sentence'].apply(fe.get_link_score)\n",
        "train_df['string_score'] = train_df['sentence'].apply(fe.get_string_score)\n",
        "\n",
        "test_df['link_score'] = test_df['sentence'].apply(fe.get_link_score)\n",
        "test_df['string_score'] = test_df['sentence'].apply(fe.get_string_score)\n",
        "\n",
        "# ----------------- 4. Normalization -----------------\n",
        "\n",
        "# Features normalization\n",
        "feature_scaler = MinMaxScaler()\n",
        "X_train = feature_scaler.fit_transform(train_df[['link_score', 'string_score']])\n",
        "X_test = feature_scaler.transform(test_df[['link_score', 'string_score']])\n",
        "\n",
        "# Target normalization\n",
        "target_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "y_train = target_scaler.fit_transform(train_df[['human_score']])\n",
        "\n",
        "# ----------------- 5. Train Model -----------------\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ----------------- 6. Predictions -----------------\n",
        "\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "\n",
        "# Convert predictions back to 0â€“100 scale\n",
        "y_pred_rescaled = target_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
        "test_df['predicted_score'] = np.clip(y_pred_rescaled, 0, 100)\n",
        "\n",
        "# ----------------- 7. Results -----------------\n",
        "\n",
        "print(\"ðŸ”¹ Trained Model Coefficients (on normalized scale):\")\n",
        "print(f\"   Link Score Weight: {model.coef_[0][0]:.2f}\")\n",
        "print(f\"   String Score Weight: {model.coef_[0][1]:.2f}\")\n",
        "\n",
        "print(\"\\nðŸ”¹ Credibility Predictions for New Data (0â€“100 scale):\")\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "print(test_df[['sentence', 'link_score', 'string_score', 'predicted_score']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANfNlKLmS_vJ",
        "outputId": "845bb8b5-e797-4145-a53a-9187297f4c21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Trained Model Coefficients (on normalized scale):\n",
            "   Link Score Weight: 0.84\n",
            "   String Score Weight: 0.14\n",
            "\n",
            "ðŸ”¹ Credibility Predictions for New Data (0â€“100 scale):\n",
            "                                                                                                                                          sentence  \\\n",
            "0                A breakthrough treatment for cancer is now available, according to this new study. http://www.breakthroughs-today.com/cancer-cure   \n",
            "1                                              The World Health Organization published a report on influenza. https://www.who.int/influenza/report   \n",
            "2                                              New research suggests probiotics are great for gut health. https://www.science.org/probiotics-study   \n",
            "3                                                   My secret formula for staying young is available here: http://www.my-blog-for-money.net/secret   \n",
            "4  Doctors are in agreement about the incredible benefits of this new diet, as reported in this journal. https://www.clinical-journal.com/new-diet   \n",
            "\n",
            "   link_score  string_score  predicted_score  \n",
            "0        50.0         40.63        29.385917  \n",
            "1       100.0        100.00       100.000000  \n",
            "2       100.0         43.76       100.000000  \n",
            "3        30.0        100.00         6.079107  \n",
            "4        50.0         36.97        28.742895  \n"
          ]
        }
      ]
    }
  ]
}