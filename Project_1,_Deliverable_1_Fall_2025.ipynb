{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using Gemini / created a dictionary .. if-ands & ML"
      ],
      "metadata": {
        "id": "syT1GxLUrmOl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "606008de",
        "outputId": "c7bb4b90-84b7-49df-92b6-2b27e43c8fc9"
      },
      "source": [
        "%pip install textstat"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.10-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (4.67.1)\n",
            "Downloading textstat-0.7.10-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.2/239.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.17.2 textstat-0.7.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIznXVLMnTu2",
        "outputId": "947c462b-f3ef-40f4-dc9e-d071b40edacc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEueEHfVnamT",
        "outputId": "7c4dcae9-956e-4410-c1e6-6a169cd8cfa5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "try:\n",
        "    SentimentIntensityAnalyzer()\n",
        "except LookupError:\n",
        "    nltk.download('vader_lexicon')\n",
        "\n",
        "# ----------------- 1. Feature Engineering Functions -----------------\n",
        "\n",
        "# Define domain scores on a 0-100 scale\n",
        "domain_credibility_scores = {\n",
        "    \".gov\": 100.0,\n",
        "    \".edu\": 95.0,\n",
        "    \"nejm.org\": 95.0,\n",
        "    \"jamanetwork.com\": 90.0,\n",
        "    \"who.int\": 100.0,\n",
        "    \".org\": 60.0,\n",
        "    \".com\": 30.0,\n",
        "    \"webmd.com\": 50.0,\n",
        "    \"wikipedia.org\": 40.0,\n",
        "    \"blogspot.com\": 10.0,\n",
        "    \"youtube.com\": 10.0,\n",
        "}\n",
        "\n",
        "def get_link_score(text_with_link: str) -> float:\n",
        "    url_pattern = re.compile(r'https?://[^\\s]+')\n",
        "    match = url_pattern.search(text_with_link)\n",
        "    link = match.group(0) if match else None\n",
        "\n",
        "    source_score = 0.0\n",
        "    if link:\n",
        "        parsed_url = urlparse(link)\n",
        "        domain = parsed_url.netloc.lower().replace('www.', '')\n",
        "\n",
        "        if domain in domain_credibility_scores:\n",
        "            source_score = domain_credibility_scores[domain]\n",
        "        else:\n",
        "            tld = '.' + domain.split('.')[-1]\n",
        "            source_score = domain_credibility_scores.get(tld, 10.0)\n",
        "\n",
        "    return round(source_score, 2)\n",
        "\n",
        "def get_string_score(text_with_link: str) -> float:\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "    clean_sentence = re.sub(r'https?://[^\\s]+', '', text_with_link)\n",
        "\n",
        "    sentiment_score = sid.polarity_scores(clean_sentence)['compound']\n",
        "\n",
        "    string_credibility_score = 100.0 - (abs(sentiment_score) * 90.0)\n",
        "\n",
        "    return round(string_credibility_score, 2)\n",
        "\n",
        "# ----------------- 2. Define Training and Testing Data -----------------\n",
        "\n",
        "# Training data (with human-assigned scores)\n",
        "training_data = {\n",
        "    'sentence': [\n",
        "        \"A study from NEJM suggests a link between this drug and reduced heart disease. https://www.nejm.org/some-article-id\",\n",
        "        \"My doctor says this supplement will boost my immune system. http://healthylifehacks.com/immune-booster\",\n",
        "        \"A new research paper on coffee is available at Harvard. https://harvard.edu/research/coffee-health\",\n",
        "        \"This new weight loss method is a miracle, as seen in this video. https://www.youtube.com/watch?v=12345\",\n",
        "        \"Vaccines for children are safe and effective, per the CDC. https://www.cdc.gov/vaccinesafety/\",\n",
        "        \"Detox tea benefits are explored in this blog. https://detox-guru.blogspot.com/2025/08/tea.html\"\n",
        "    ],\n",
        "    'human_score': [90.0, 30.0, 95.0, 20.0, 100.0, 40.0]\n",
        "}\n",
        "training_df = pd.DataFrame(training_data)\n",
        "\n",
        "# Testing data (new, unseen data without scores)\n",
        "testing_data = {\n",
        "    'sentence': [\n",
        "        \"A breakthrough treatment for cancer is now available, according to this new study. http://www.breakthroughs-today.com/cancer-cure\",\n",
        "        \"The World Health Organization published a report on influenza. https://www.who.int/influenza/report\",\n",
        "        \"New research suggests probiotics are great for gut health. https://www.science.org/probiotics-study\",\n",
        "        \"My secret formula for staying young is available here: http://www.my-blog-for-money.net/secret\",\n",
        "        \"Doctors are in agreement about the incredible benefits of this new diet, as reported in this journal. https://www.clinical-journal.com/new-diet\"\n",
        "    ]\n",
        "}\n",
        "testing_df = pd.DataFrame(testing_data)\n",
        "\n",
        "# ----------------- 3. Prepare and Train the Model -----------------\n",
        "\n",
        "# Prepare training features and labels\n",
        "training_df['link_score'] = training_df['sentence'].apply(get_link_score)\n",
        "training_df['string_score'] = training_df['sentence'].apply(get_string_score)\n",
        "X_train = training_df[['link_score', 'string_score']]\n",
        "y_train = training_df['human_score']\n",
        "\n",
        "# Train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ----------------- 4. Make Predictions on Testing Data -----------------\n",
        "\n",
        "# Prepare testing features\n",
        "testing_df['link_score'] = testing_df['sentence'].apply(get_link_score)\n",
        "testing_df['string_score'] = testing_df['sentence'].apply(get_string_score)\n",
        "X_test = testing_df[['link_score', 'string_score']]\n",
        "\n",
        "# Make predictions using the trained model\n",
        "testing_df['predicted_score'] = model.predict(X_test)\n",
        "\n",
        "# ----------------- 5. Display Final Results -----------------\n",
        "\n",
        "print(\"Trained Model Coefficients:\")\n",
        "print(f\"Link Score Weight: {model.coef_[0]:.2f}\")\n",
        "print(f\"String Score Weight: {model.coef_[1]:.2f}\")\n",
        "\n",
        "print(\"\\nCredibility Predictions for New Data:\")\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "print(testing_df[['sentence', 'link_score', 'string_score', 'predicted_score']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kE3d0eYJQ4yg",
        "outputId": "dfe8c767-866a-472b-e026-9f60bcf03204"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Model Coefficients:\n",
            "Link Score Weight: 0.88\n",
            "String Score Weight: -0.00\n",
            "\n",
            "Credibility Predictions for New Data:\n",
            "                                                                                                                                          sentence  \\\n",
            "0                A breakthrough treatment for cancer is now available, according to this new study. http://www.breakthroughs-today.com/cancer-cure   \n",
            "1                                              The World Health Organization published a report on influenza. https://www.who.int/influenza/report   \n",
            "2                                              New research suggests probiotics are great for gut health. https://www.science.org/probiotics-study   \n",
            "3                                                   My secret formula for staying young is available here: http://www.my-blog-for-money.net/secret   \n",
            "4  Doctors are in agreement about the incredible benefits of this new diet, as reported in this journal. https://www.clinical-journal.com/new-diet   \n",
            "\n",
            "   link_score  string_score  predicted_score  \n",
            "0        30.0         40.63        36.057023  \n",
            "1       100.0        100.00        97.774264  \n",
            "2        60.0         43.76        62.561113  \n",
            "3        10.0        100.00        18.239333  \n",
            "4        30.0         36.97        36.065854  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using WYN360"
      ],
      "metadata": {
        "id": "WA0INtIArxSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from urllib.parse import urlparse\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "try:\n",
        "    SentimentIntensityAnalyzer()\n",
        "except LookupError:\n",
        "    nltk.download('vader_lexicon')\n",
        "\n",
        "\n",
        "class CredibilityScorer:\n",
        "    def __init__(self):\n",
        "        # Previous initializations remain the same\n",
        "        self.credible_domains = {\n",
        "            'nature.com': 1.0, 'science.org': 1.0, 'edu': 0.9,\n",
        "            'gov': 0.9, 'org': 0.7, 'com': 0.5,\n",
        "            'thelancet.com': 1.0, 'sciencedirect.com': 0.9,\n",
        "            'springer.com': 0.9, 'ieee.org': 0.9, 'acm.org': 0.9,\n",
        "            'nih.gov': 1.0, # Added NIH for testing data\n",
        "            'clinical-journal.com': 0.8 # Added for testing data\n",
        "        }\n",
        "\n",
        "        # Add academic and scientific websites\n",
        "        self.academic_sites = {\n",
        "            'researchgate.net', 'academia.edu', 'scholar.google.com',\n",
        "            'arxiv.org', 'pubmed.ncbi.nlm.nih.gov', 'jstor.org'\n",
        "        }\n",
        "\n",
        "        # Initialize VADER sentiment analyzer\n",
        "        self.sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "        # Previous initializations continue...\n",
        "\n",
        "    def extract_urls(self, text):\n",
        "        # URL regex pattern\n",
        "        url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "        return re.findall(url_pattern, text)\n",
        "\n",
        "    def score_url(self, url):\n",
        "        try:\n",
        "            domain = urlparse(url).netloc.lower()\n",
        "            base_domain = '.'.join(domain.split('.')[-2:])\n",
        "\n",
        "            # Check if it's an academic site\n",
        "            if domain in self.academic_sites:\n",
        "                return 1.0\n",
        "\n",
        "            # Check credible domains\n",
        "            for credible_domain, score in self.credible_domains.items():\n",
        "                if credible_domain in domain:\n",
        "                    return score\n",
        "\n",
        "            return 0.3  # Default score for unknown domains\n",
        "\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def get_string_score(self, text_with_link: str) -> float:\n",
        "        clean_sentence = re.sub(r'https?://[^\\s]+', '', text_with_link)\n",
        "        sentiment_score = self.sid.polarity_scores(clean_sentence)['compound']\n",
        "        # Scale the sentiment score to a 0-100 range, where a neutral or objective\n",
        "        # tone (sentiment_score close to 0) gets a higher credibility score.\n",
        "        # Highly positive or negative sentiment reduces the string credibility.\n",
        "        string_credibility_score = 100.0 - (abs(sentiment_score) * 90.0)\n",
        "        return round(string_credibility_score, 2)\n",
        "\n",
        "    def calculate_total_score(self, text):\n",
        "        link_score = 0.0\n",
        "        urls = self.extract_urls(text)\n",
        "        if urls:\n",
        "            # Get the maximum score from all found URLs\n",
        "            link_score = max(self.score_url(url) for url in urls) * 100\n",
        "\n",
        "        string_score = self.get_string_score(text)\n",
        "\n",
        "        # Combine scores (you can adjust the weights here)\n",
        "        # This is a simplified combination, you might use a trained model as in the previous cells\n",
        "        # For this example, let's give more weight to the link score if available\n",
        "        if urls:\n",
        "             total_score = (link_score * 0.7) + (string_score * 0.3) # Example weighting\n",
        "        else:\n",
        "             total_score = string_score # If no link, rely only on string sentiment\n",
        "\n",
        "        return round(total_score, 2)\n",
        "\n",
        "\n",
        "# Example usage with URLs\n",
        "def main():\n",
        "    scorer = CredibilityScorer()\n",
        "\n",
        "    test_strings = [\n",
        "        \"According to a 2024 study published in Nature (https://nature.com/articles/xxx), researchers at MIT found that 87% of renewable energy implementations reduced carbon emissions by an average of 45% (p<0.001).\",\n",
        "\n",
        "        \"A comprehensive review on PubMed (https://pubmed.ncbi.nlm.nih.gov/12345) and The Lancet (https://www.thelancet.com/article/789) shows strong evidence for vaccine efficacy.\",\n",
        "\n",
        "        \"New research from Stanford University (https://stanford.edu/research/123) and published on arXiv (https://arxiv.org/abs/1234.5678) demonstrates breakthrough in quantum computing.\",\n",
        "\n",
        "        \"SHOCKING weight loss discovery! Read more at https://sketchy-diet-pills.com/amazing-results\",\n",
        "\n",
        "        \"According to https://weather.com/climate-change, scientists suggest potential changes in weather patterns.\"\n",
        "    ]\n",
        "\n",
        "    for i, text in enumerate(test_strings, 1):\n",
        "        score = scorer.calculate_total_score(text)\n",
        "        print(f\"\\nExample {i}:\")\n",
        "        print(f\"Text: {text}\")\n",
        "        print(f\"Credibility Score: {score}/100\")\n",
        "\n",
        "        # Print URLs found in the text\n",
        "        urls = scorer.extract_urls(text)\n",
        "        if urls:\n",
        "            print(\"URLs found:\")\n",
        "            for url in urls:\n",
        "                print(f\"- {url} (Domain score: {scorer.score_url(url)})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cHUM0lsQtSna",
        "outputId": "0eb1e15b-2cd5-4e57-965c-9457a9dbe0f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example 1:\n",
            "Text: According to a 2024 study published in Nature (https://nature.com/articles/xxx), researchers at MIT found that 87% of renewable energy implementations reduced carbon emissions by an average of 45% (p<0.001).\n",
            "Credibility Score: 92.62/100\n",
            "URLs found:\n",
            "- https://nature.com/articles/xxx), (Domain score: 1.0)\n",
            "\n",
            "Example 2:\n",
            "Text: A comprehensive review on PubMed (https://pubmed.ncbi.nlm.nih.gov/12345) and The Lancet (https://www.thelancet.com/article/789) shows strong evidence for vaccine efficacy.\n",
            "Credibility Score: 82.49/100\n",
            "URLs found:\n",
            "- https://pubmed.ncbi.nlm.nih.gov/12345) (Domain score: 1.0)\n",
            "- https://www.thelancet.com/article/789) (Domain score: 0.5)\n",
            "\n",
            "Example 3:\n",
            "Text: New research from Stanford University (https://stanford.edu/research/123) and published on arXiv (https://arxiv.org/abs/1234.5678) demonstrates breakthrough in quantum computing.\n",
            "Credibility Score: 100.0/100\n",
            "URLs found:\n",
            "- https://stanford.edu/research/123) (Domain score: 0.9)\n",
            "- https://arxiv.org/abs/1234.5678) (Domain score: 1.0)\n",
            "\n",
            "Example 4:\n",
            "Text: SHOCKING weight loss discovery! Read more at https://sketchy-diet-pills.com/amazing-results\n",
            "Credibility Score: 45.55/100\n",
            "URLs found:\n",
            "- https://sketchy-diet-pills.com/amazing-results (Domain score: 0.5)\n",
            "\n",
            "Example 5:\n",
            "Text: According to https://weather.com/climate-change, scientists suggest potential changes in weather patterns.\n",
            "Credibility Score: 65.0/100\n",
            "URLs found:\n",
            "- https://weather.com/climate-change, (Domain score: 0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best model may be a hybrid of these two codes. The first code uses ML, while the second code uses a rule-based scoring system. Here is what a hybrid model would like like:"
      ],
      "metadata": {
        "id": "zAJ3ARWF7jiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "\n",
        "# ----------------- 1. Hybrid Feature Engineering -----------------\n",
        "\n",
        "class HybridCredibilityFeatures:\n",
        "    def __init__(self):\n",
        "        self.credible_domains = {\n",
        "            'nature.com': 1.0, 'science.org': 1.0, 'edu': 0.9,\n",
        "            'gov': 0.9, 'org': 0.7, 'com': 0.5,\n",
        "            'thelancet.com': 1.0, 'sciencedirect.com': 0.9,\n",
        "            'springer.com': 0.9, 'ieee.org': 0.9, 'acm.org': 0.9,\n",
        "            'nih.gov': 1.0, 'clinical-journal.com': 0.8,\n",
        "            'who.int': 1.0, 'nejm.org': 1.0, 'jamanetwork.com': 0.9,\n",
        "            'webmd.com': 0.6, 'wikipedia.org': 0.4,\n",
        "            'blogspot.com': 0.2, 'youtube.com': 0.2\n",
        "        }\n",
        "        self.academic_sites = {\n",
        "            'researchgate.net', 'academia.edu', 'scholar.google.com',\n",
        "            'arxiv.org', 'pubmed.ncbi.nlm.nih.gov', 'jstor.org'\n",
        "        }\n",
        "        self.sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "    def extract_urls(self, text):\n",
        "        url_pattern = r'https?://[^\\s]+'\n",
        "        return re.findall(url_pattern, text)\n",
        "\n",
        "    def score_url(self, url):\n",
        "        try:\n",
        "            domain = urlparse(url).netloc.lower()\n",
        "            base_domain = '.'.join(domain.split('.')[-2:])\n",
        "\n",
        "            if domain in self.academic_sites:\n",
        "                return 1.0\n",
        "            for credible_domain, score in self.credible_domains.items():\n",
        "                if credible_domain in domain or credible_domain in base_domain:\n",
        "                    return score\n",
        "            return 0.3  # Default for unknown\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def get_link_score(self, text):\n",
        "        urls = self.extract_urls(text)\n",
        "        if urls:\n",
        "            return max(self.score_url(url) for url in urls) * 100\n",
        "        return 0.0\n",
        "\n",
        "    def get_string_score(self, text):\n",
        "        clean_sentence = re.sub(r'https?://[^\\s]+', '', text)\n",
        "        sentiment_score = self.sid.polarity_scores(clean_sentence)['compound']\n",
        "        return round(100.0 - (abs(sentiment_score) * 90.0), 2)\n",
        "\n",
        "# ----------------- 2. Training & Testing Data -----------------\n",
        "\n",
        "training_data = {\n",
        "    'sentence': [\n",
        "        \"A study from NEJM suggests a link between this drug and reduced heart disease. https://www.nejm.org/some-article-id\",\n",
        "        \"My doctor says this supplement will boost my immune system. http://healthylifehacks.com/immune-booster\",\n",
        "        \"A new research paper on coffee is available at Harvard. https://harvard.edu/research/coffee-health\",\n",
        "        \"This new weight loss method is a miracle, as seen in this video. https://www.youtube.com/watch?v=12345\",\n",
        "        \"Vaccines for children are safe and effective, per the CDC. https://www.cdc.gov/vaccinesafety/\",\n",
        "        \"Detox tea benefits are explored in this blog. https://detox-guru.blogspot.com/2025/08/tea.html\"\n",
        "    ],\n",
        "    'human_score': [90.0, 30.0, 95.0, 20.0, 100.0, 40.0]\n",
        "}\n",
        "train_df = pd.DataFrame(training_data)\n",
        "\n",
        "test_data = {\n",
        "    'sentence': [\n",
        "        \"A breakthrough treatment for cancer is now available, according to this new study. http://www.breakthroughs-today.com/cancer-cure\",\n",
        "        \"The World Health Organization published a report on influenza. https://www.who.int/influenza/report\",\n",
        "        \"New research suggests probiotics are great for gut health. https://www.science.org/probiotics-study\",\n",
        "        \"My secret formula for staying young is available here: http://www.my-blog-for-money.net/secret\",\n",
        "        \"Doctors are in agreement about the incredible benefits of this new diet, as reported in this journal. https://www.clinical-journal.com/new-diet\"\n",
        "    ]\n",
        "}\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "# ----------------- 3. Feature Extraction -----------------\n",
        "\n",
        "fe = HybridCredibilityFeatures()\n",
        "\n",
        "train_df['link_score'] = train_df['sentence'].apply(fe.get_link_score)\n",
        "train_df['string_score'] = train_df['sentence'].apply(fe.get_string_score)\n",
        "\n",
        "test_df['link_score'] = test_df['sentence'].apply(fe.get_link_score)\n",
        "test_df['string_score'] = test_df['sentence'].apply(fe.get_string_score)\n",
        "\n",
        "# ----------------- 4. Normalization -----------------\n",
        "\n",
        "# Features normalization\n",
        "feature_scaler = MinMaxScaler()\n",
        "X_train = feature_scaler.fit_transform(train_df[['link_score', 'string_score']])\n",
        "X_test = feature_scaler.transform(test_df[['link_score', 'string_score']])\n",
        "\n",
        "# Target normalization\n",
        "target_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "y_train = target_scaler.fit_transform(train_df[['human_score']])\n",
        "\n",
        "# ----------------- 5. Train Model -----------------\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ----------------- 6. Predictions -----------------\n",
        "\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "\n",
        "# Convert predictions back to 0–100 scale\n",
        "y_pred_rescaled = target_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
        "test_df['predicted_score'] = np.clip(y_pred_rescaled, 0, 100)\n",
        "\n",
        "# ----------------- 7. Results -----------------\n",
        "\n",
        "print(\"🔹 Trained Model Coefficients (on normalized scale):\")\n",
        "print(f\"   Link Score Weight: {model.coef_[0][0]:.2f}\")\n",
        "print(f\"   String Score Weight: {model.coef_[0][1]:.2f}\")\n",
        "\n",
        "print(\"\\n🔹 Credibility Predictions for New Data (0–100 scale):\")\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "print(test_df[['sentence', 'link_score', 'string_score', 'predicted_score']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRk2wLsj8vLR",
        "outputId": "5ea14300-6fcf-4c40-b16b-cd8baa7e42de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Trained Model Coefficients (on normalized scale):\n",
            "   Link Score Weight: 0.84\n",
            "   String Score Weight: 0.14\n",
            "\n",
            "🔹 Credibility Predictions for New Data (0–100 scale):\n",
            "                                                                                                                                          sentence  \\\n",
            "0                A breakthrough treatment for cancer is now available, according to this new study. http://www.breakthroughs-today.com/cancer-cure   \n",
            "1                                              The World Health Organization published a report on influenza. https://www.who.int/influenza/report   \n",
            "2                                              New research suggests probiotics are great for gut health. https://www.science.org/probiotics-study   \n",
            "3                                                   My secret formula for staying young is available here: http://www.my-blog-for-money.net/secret   \n",
            "4  Doctors are in agreement about the incredible benefits of this new diet, as reported in this journal. https://www.clinical-journal.com/new-diet   \n",
            "\n",
            "   link_score  string_score  predicted_score  \n",
            "0        50.0         40.63        29.385917  \n",
            "1       100.0        100.00       100.000000  \n",
            "2       100.0         43.76       100.000000  \n",
            "3        30.0        100.00         6.079107  \n",
            "4        50.0         36.97        28.742895  \n"
          ]
        }
      ]
    }
  ]
}